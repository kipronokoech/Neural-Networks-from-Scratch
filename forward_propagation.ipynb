{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "miniature-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 shape:  (4, 3)\n",
      "w2 shape:  (1, 4)\n",
      "X shape:  (3, 395)\n",
      "w1 shape:  (4, 3)\n",
      "b1 shape (4, 1)\n",
      "w2 shape:  (1, 4)\n",
      "b2 shape (1, 1)\n",
      "f1 shape (4, 395)\n",
      "z2.shape (1, 395)\n",
      "yhat shape (1, 395)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class OurNeuralNet(object):\n",
    "    def __init__(self, X, layers):\n",
    "        self.X = X\n",
    "        self.layers = layers\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        \"\"\"\n",
    "        Argument: value(s) x\n",
    "        Returns: f(x) where f is sigmoig activativation\n",
    "        \"\"\" \n",
    "        # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def parameters_initialization(self):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        - a list of number of neurons in each layer\n",
    "\n",
    "        Returns:\n",
    "        params -- python dictionary containing initial parameter values:\n",
    "        W1 - weight matrix of shape (n1, n0)\n",
    "        b1 - bias vector of shape (n1, 1)\n",
    "        W2 - weight matrix of shape (n2, n1)\n",
    "        b2 - bias vector of shape (n2, 1)\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Number of neurons in each layer. We just have 3 layers\n",
    "        n0, n1, n2 = self.layers\n",
    "        np.random.seed(3)\n",
    "        \n",
    "        #Generating parameter values for layer 1\n",
    "        w1 = np.random.randn(n1,n0) * 0.1\n",
    "        b1 = np.zeros((n1,1))\n",
    "        print(\"w1 shape: \", w1.shape)\n",
    "        \n",
    "        #Generating initial parameter values for layer 2\n",
    "        w2 = np.random.randn(n2,n1) * 0.1\n",
    "        b2 = np.zeros((n2,1))\n",
    "        print(\"w2 shape: \", w2.shape)\n",
    "\n",
    "        params = {\"w1\": w1,\n",
    "                    \"b1\": b1,\n",
    "                        \"w2\": w2,\n",
    "                          \"b2\": b2}\n",
    "\n",
    "        return params\n",
    "    \n",
    "    def forward_propagation(self):\n",
    "        \"\"\"\n",
    "        Call parameters_initialization() function\n",
    "        \n",
    "        Returns:\n",
    "        yhat - model output on one forward pass for all the training examples\n",
    "        layer_ouputs - a dictionary containing model outputs at each layer.\n",
    "        \"\"\"\n",
    "        # Call function to initialize parameters\n",
    "        parameters = self.parameters_initialization()\n",
    "        print(\"X shape: \", self.X.shape)\n",
    "        w1 = parameters[\"w1\"]\n",
    "        print(\"w1 shape: \", w1.shape)\n",
    "        b1 = parameters[\"b1\"]\n",
    "        print(\"b1 shape\", b1.shape)\n",
    "        w2 = parameters[\"w2\"]\n",
    "        print(\"w2 shape: \", w2.shape)\n",
    "        b2 = parameters[\"b2\"]\n",
    "        print(\"b2 shape\", b2.shape)\n",
    "\n",
    "        # Perform computations for each layer\n",
    "        z1 = np.dot(w1, self.X) + b1\n",
    "        f1 = self.sigmoid(z1)\n",
    "        print(\"f1 shape\", f1.shape)\n",
    "        z2 = np.dot(w2, f1) + b2\n",
    "        print(\"z2.shape\", z2.shape)\n",
    "        yhat = self.sigmoid(z2)\n",
    "        print(\"yhat shape\", yhat.shape)\n",
    "\n",
    "        # Just to make sure that the output is of the dimension\n",
    "        # we expect\n",
    "        # It should be a vector of the predictions for the for all examples\n",
    "        # self.X.shape[1] - number of training examples\n",
    "        assert(yhat.shape == (1, self.X.shape[1]))\n",
    "        \n",
    "        layer_outputs = {\"z1\": z1,\n",
    "                 \"f1\": f1,\n",
    "                 \"z2\": z2,\n",
    "                 \"yhat\": yhat}\n",
    "\n",
    "        return yhat, layer_outputs\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"https://kipronokoech.github.io/assets/datasets/marks.csv\")\n",
    "#df = pd.read_csv(\"marks.csv\")\n",
    "X = df.drop([\"y\"], axis=1) # feature matrix\n",
    "y = df[\"y\"] # target variable\n",
    "\n",
    "n0 = X.shape[1] #input size = number of features\n",
    "n1 = 4 # 4 neurons on the hidden\n",
    "n2 = 1 # one neuron for output\n",
    "\n",
    "layers = (n0, n1, n2)\n",
    "# note: we need X in the dimension X (#features, #training examples)\n",
    "# therefore we transpose the feature matrix, that is, X.T\n",
    "s = OurNeuralNet(X= X.T, layers=layers)\n",
    "y_hat, _ = s.forward_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-riverside",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
